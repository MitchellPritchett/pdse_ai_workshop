{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[PDSE]AI_workshop_week10(pytorch_in_1hour_파이토치_기초_1시간컷하기_with_ans).ipynb의 사본",
      "provenance": [],
      "authorship_tag": "ABX9TyO+u9q7Uhf77ZEp84jByQYm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MitchellPritchett/pdse_ai_workshop/blob/main/%5BPDSE%5DAI_workshop_week10(pytorch_in_1hour_%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EA%B8%B0%EC%B4%88_1%EC%8B%9C%EA%B0%84%EC%BB%B7%ED%95%98%EA%B8%B0_with_ans)_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10주차\n",
        "이 코드는 ***파이토치 첫걸음*** 책과 교재의 오픈 소싱된 코드를 기반으로 합니다.  \n",
        "파이토치로 앞선 주차에서 공부한 내용들을 구현해보겠습니다."
      ],
      "metadata": {
        "id": "juo-QE0bD7Zi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why Use Pytorch?\n",
        "- 넘파이로 한다고 하면, 모든 미분 식을 직접 계산하고 코드로 작성해야 합니다. ➡ 파이토치는 함수가 있습니다.\n",
        "- GPU를 통한 연산을 할 수 있습니다. 파이토치는 내부적으로 CUDA, cuDNN 이라는 API를 통해서 GPU 연산을 할 수 있고, 연산 속도 차이가 엄청 큽니다.\n",
        "    - CUDA는 엔비디아가 GPU를 통한 연산을 가능하게 만든 API 모델\n",
        "    - cuDNN은 CUDA를 이용해 딥러닝 연산을 가속해주는 라이브러리\n",
        "- 텐서플로도 GPU를 연산에 사용하는 프레임워크인데, 텐서플로는 Define and Run인 반면에 파이토치는 Define by Run\n",
        "- 자체 운영 포럼이 있어서 질문을 올리면 파이토치 개발자들이 직접 답을 달아주기도 합니다.\n"
      ],
      "metadata": {
        "id": "a0fDawRZJto0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation\n",
        "로컬에 설치하는 경우에는 본인 컴퓨터 사양과 운영체제에 맞게 설치를 해주시면 됩니다.\n",
        "파이토치 사용을 위해서는 파이썬 -> 쿠다 -> 쿠디엔엔 -> 파이토치 순서로 설치합니다.  \n",
        "서버를 다른 용도로 사용할 수도 있기 때문에 아나콘다의 가상환경 설정 프로그램을 이용합시다.  \n",
        "여기서는 코랩 환경을 전제하겠습니다. 코랩에는 이미 CUDA와 cuDNN, 파이토치가 깔려 있습니다.\n",
        "- 파이썬 버젼 체크 (Python version Check)\n",
        "- 파이토치 설치 (PyTorch Installation)\n",
        "- 쿠다 및 CuDNN 체크 (Cuda & CuDNN Check)"
      ],
      "metadata": {
        "id": "zcQr0Mn2KpH3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06f_Mo-IqpAK"
      },
      "source": [
        "## 1. Python Version Check\n",
        "파이썬 버젼 체크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKr8deu5qQxV"
      },
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHDAz4Y1qtQR"
      },
      "source": [
        "## 2. PyTorch Installation\n",
        "- 구글 코랩 버젼에 따라 파이토치가 설치되어 있을수도 있고 아닐 수도 있습니다.\n",
        "- 설치가 안되어 있을 경우 아래와 같은 명령어로 설치하면 됩니다.\n",
        "- !pip3 install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjXpmFmsoNir"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca5b9q88oNu_"
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI5zft-7r-G5"
      },
      "source": [
        "## 3. Cuda & cudnn Version Check\n",
        "- 파이토치를 통해 각각 몇 버젼이 설치 되어있는지 확인해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWzr0ZYuoAx3"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(\"Torch version:{}\".format(torch.__version__))\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPs2iVjbsaHb"
      },
      "source": [
        "## 4. Command Line cuda & cudnn Check\n",
        "- 쿠다 및 CuDNN 버젼은 커맨드라인 명령어로도 확인 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr-joKu0sGf5"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZMgAzL3sPQ6"
      },
      "source": [
        "!cat /usr/include/x86_64-linux-gnu/cudnn_v*.h | grep CUDNN_MAJOR -A 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPvgso5LuCWF"
      },
      "source": [
        "# 5. PyTorch CPU & GPU Tensor Check\n",
        "- 파이토치 텐서를 생성해봄으로써 제대로 설치 되었는지, 잘 동작하는지 확인해줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBgm1epHwTSA"
      },
      "source": [
        "### 5-1 Create CPU tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nZVqGHxt_8D"
      },
      "source": [
        "# https://pytorch.org/docs/stable/torch.html?highlight=tensor#torch.tensor\n",
        "# 0으로 차있는 2x3 형태의 텐서를 생성합니다.\n",
        "cpu_tensor = torch.zeros(2,3)\n",
        "print(cpu_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCxV8pxHwZc6"
      },
      "source": [
        "### 5-2 Allocate tensor on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyDZg5BbuSe9"
      },
      "source": [
        "# https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.device\n",
        "# 어느 장치(cpu 혹은 gpu)에 텐서를 올릴지 지정합니다.\n",
        "# 아래는 torch.device라는 함수를 사용해 gpu로 장치를 지정합니다. \n",
        "device = torch.device('cuda')\n",
        "\n",
        "# https://pytorch.org/docs/stable/cuda.html?highlight=available#torch.cuda.is_available\n",
        "# gpu가 사용 가능한지 확인해줍니다.\n",
        "if torch.cuda.is_available():\n",
        "  \n",
        "  # https://pytorch.org/docs/stable/tensors.html?highlight=#torch.Tensor.to\n",
        "  # cpu에 있었던 텐서를 to 함수를 이용해 지정해놓은 장치(여기서는 gpu)로 올려줍니다.\n",
        "  gpu_tensor = cpu_tensor.to(device)\n",
        "  print(gpu_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKRTa76_wiGA"
      },
      "source": [
        "### 5-3 Reallocate tensor back on CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NIT1b6vvf8a"
      },
      "source": [
        "# device 함수와 to 함수를 이용해 gpu에 있던 텐서를 다시 cpu로 옮겨올 수 있습니다.\n",
        "cpu_tensor_back = gpu_tensor.to(torch.device('cpu'))\n",
        "cpu_tensor_back"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO79CKh9DdUb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJTsOFV5LZj1"
      },
      "source": [
        "# 선형 회귀 (Linear Regression)\n",
        "\n",
        "- 선형 관계를 가지고 있는 데이터 (Linear Data)\n",
        "- 선형 모델 (Linear Model)\n",
        "- y = 2x+3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrmW0T0nMHLQ"
      },
      "source": [
        "# 파이토치가 설치되어 있는지 확인해줍니다.\n",
        "!pip3 install torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7pum8kHpo4Q"
      },
      "source": [
        "## 필요한 라이브러리를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l5PEorHLbLk"
      },
      "source": [
        "# 넘파이와 파이토치를 불러옵니다.\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Neural Network의 약자로 인공신경망 연산들이 들어가 있습니다. (ex. Linear, Convolution, RNN 등등)\n",
        "import torch.nn as nn           \n",
        "\n",
        "# 모델을 최적화 하는데 필요한 최적화 함수들이 들어가 있습니다 (ex. SGD, ADAM, LBFGS 등등)\n",
        "import torch.optim as optim\n",
        "\n",
        "# 텐서를 초기화 하는 함수들이 들어가 있습니다. (ex. uniform, normal, xavier 등등)\n",
        "import torch.nn.init as init\n",
        "\n",
        "# 데이터나 학습 결과를 출력하기 위해 사용합니다.\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLS6gONcps1j"
      },
      "source": [
        "## 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1gE7iPuLdl8"
      },
      "source": [
        "# 데이터의 개수는 1000개, 학습 횟수는 500회로 지정해줍니다. \n",
        "# 이는 임의로 지정한 수치입니다.\n",
        "\n",
        "num_data = 1000 \n",
        "num_epoch = 500\n",
        "\n",
        "# 데이터에 추가할 노이즈를 정규분포를 따르게 만들어줍니다. \n",
        "# 이때 평균은 디폴트로 0, 편차는 0.2로 임의로 지정했습니다.\n",
        "noise = init.normal_(torch.FloatTensor(num_data,1),std=0.2)\n",
        "\n",
        "# x 는 -10에서 10에서 uniform 하게 생성합니다. \n",
        "# 이렇게 되면 x는 1000x1 형태를 가지고 -10에서 10 사이의 값들을 uniform 하게 갖게 됩니다.\n",
        "x = init.uniform_(torch.Tensor(num_data,1),-10,10)\n",
        "\n",
        "# 연산 그래프를 정의합니다.\n",
        "y = 2*x+3\n",
        "\n",
        "# y에 노이즈를 더해 y_noise를 만들어줍니다. \n",
        "# 학습때 y_noise를 목표값으로 사용합니다.\n",
        "# 이렇게 하는 이유는 실제 데이터를 사용할 때 여러 측정과정에서 노이즈가 추가되는 경우가 많기 때문입니다.\n",
        "y_noise = y+noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m95kllRxpxgj"
      },
      "source": [
        "## 데이터 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TqGiPWkMQyk"
      },
      "source": [
        "# https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.scatter.html\n",
        "# matplotlib의 scatter 함수를 사용해 학습 데이터를 확인합니다.\n",
        "\n",
        "# figure의 크기를 지정해줍니다.\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "# x축에는 x를 사용하고 y축에는 y_noise를 사용해 scatter plot 해줍니다.\n",
        "# 이때 점의 크기는 7, 점의 색상은 회색으로 임의로 지정했습니다.\n",
        "plt.scatter(x.numpy(),y_noise.numpy(),s=7,c=\"gray\")\n",
        "\n",
        "# figure의 x,y 축 범위를 지정해줍니다.\n",
        "plt.axis([-12, 12, -25, 25])\n",
        "\n",
        "# figure를 출력합니다.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaXA1tx9p1_k"
      },
      "source": [
        "## 모델, 손실함수, 최적화 함수 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c2kT4dkMb6B"
      },
      "source": [
        "# 선형 모델을 생성합니다.\n",
        "# 입력으로 들어오는 x가 1000x1 의 형태를 가지고 있고 여기서 특성의 개수는 1개이기 때문에 앞에 1이 들어가게 됩니다. Linear(1,?)\n",
        "# 출력으로 기대하는 값 또한 1000x1 의 형태이기 때문에 특성의 개수가 1개. 그렇기 때문에 뒤에 1이 들어갑니다.      Linear(?,1)\n",
        "model = nn.Linear(1,1)\n",
        "\n",
        "# 손실 함수를 지정해줍니다.\n",
        "# 임의로 L1 손실을 사용했습니다.\n",
        "loss_func = nn.L1Loss()\n",
        "\n",
        "# 최적화 함수를 지정해줍니다.\n",
        "# 이때 인수로 학습의 대상이 되는 모델의 변수(model.parameters())를 전달합니다.\n",
        "# 또한 학습률은 0.01로 임의로 지정했습니다.\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okLqOLTZp7hP"
      },
      "source": [
        "## 모델 학습 및 중간 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJbBMTscMr0n"
      },
      "source": [
        "# 손실이 어떻게 변하는지 확인하기 위해 loss_arr를 만들어 기록합니다.\n",
        "loss_arr =[]\n",
        "\n",
        "# 또한 목표값은 y_noise로 지정해줍니다.\n",
        "label = y_noise\n",
        "\n",
        "# 500으로 지정했던 학습 횟수만큼 반복합니다.\n",
        "for i in range(num_epoch):\n",
        "  \n",
        "    # 이전 학습의 기울기를 지우고 최적화 함수를 초기화해줍니다.\n",
        "    # 기울기를 지우지 않으면 기존의 업데이트 때문에 학습이 잘 이루어지지 않습니다.\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 입력값 x를 모델에 넣어 결과값을 얻습니다.\n",
        "    output = model(x)\n",
        "    \n",
        "    # 결과값과 목표값의 차이를 L1 손실 함수로 구해줍니다.\n",
        "    loss = loss_func(output,label)\n",
        "    \n",
        "    # 손실에 대한 기울기를 구합니다.\n",
        "    loss.backward()\n",
        "    \n",
        "    # 구한 기울기를 이용해 모델의 변수를 업데이트 합니다.\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 10번 마다 모델의 변수가 어떻게 변하고 있는지 출력해줍니다.\n",
        "    if i % 10 == 0:\n",
        "        # https://pytorch.org/docs/stable/tensors.html?highlight=detach#torch.Tensor.detach\n",
        "        # 현재 연산 그래프에 속해있는 x, output 값을 detach를 통해 분리하고, 텐서를 넘파이 배열로 바꿔서 plt.scatter에 전달합니다.\n",
        "        plt.scatter(x.detach().numpy(),output.detach().numpy())\n",
        "        plt.axis([-10, 10, -30, 30])\n",
        "        plt.show()\n",
        "        print(loss.data)\n",
        "        \n",
        "    # 손실을 loss_arr에 추가해줍니다.\n",
        "    loss_arr.append(loss.detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yydtfhYEqB0e"
      },
      "source": [
        "## 학습 후 데이터와 모델 결과값 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Keizg9-LWQhP"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.scatter(x.numpy(),y_noise.numpy(),s=5,c=\"gray\")\n",
        "plt.scatter(x.detach().numpy(),output.detach().numpy(),s=5,c=\"red\")\n",
        "plt.axis([-10, 10, -30, 30])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERafFOhXPLnw"
      },
      "source": [
        "## 손실 그래프"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpd3fxK0Mvt6"
      },
      "source": [
        "# matplotlib의 plot 함수를 이용해 손실이 어떻게 줄어가는지 확인합니다. \n",
        "plt.plot(loss_arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaieW3joqI9z"
      },
      "source": [
        "## 학습 후 모델 변수 값 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0FdZBf_NIJX"
      },
      "source": [
        "# 현재 모델은 weight와 bias을 변수로 가지고 있는데 그 값들이 학습 후 실제 몇인지 수치적으로 확인해봅니다.\n",
        "param_list = list(model.parameters())\n",
        "print(\"Weight:\",param_list[0].item(),\"\\nBias:  \",param_list[1].item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaEdE17jpRlm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiVaMkwNSpCx"
      },
      "source": [
        "# 인공신경망 모델의 학습\n",
        "\n",
        "- 설명한 부분을 제외하고 주석을 달았습니다.\n",
        "- y = x^2+3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0eJo_1TsZIw"
      },
      "source": [
        "## 필요한 라이브러리 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAIfLqxsSmrJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfXQ4EJ1sR5Y"
      },
      "source": [
        "## 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrRWI9QBsI8U"
      },
      "source": [
        "num_data = 1000\n",
        "num_epoch = 10000\n",
        "\n",
        "noise = init.normal_(torch.FloatTensor(num_data,1),std=1)\n",
        "x = init.uniform_(torch.Tensor(num_data,1),-15,15)\n",
        "y = (x**2) + 3 \n",
        "y_noise = y + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTNOAQgwscKV"
      },
      "source": [
        "# 모델, 손실 함수, 최적화 함수 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJMeNlCWsJEp"
      },
      "source": [
        "# 3장의 예시처럼 하나의 값이 들어가서 하나의 값이 나오기 때문에 모델의 처음과 끝 특성의 개수는 1개입니다.\n",
        "\n",
        "# https://pytorch.org/docs/stable/nn.html?highlight=sequential\n",
        "# torch.nn.Sequential\n",
        "# Sequential 모듈은 다양한 모듈을 담을 수 있는 일종의 리스트라고 보면 됩니다.\n",
        "# Sequential 에 정의된 순서대로 연산이 진행되며, 많은 연산을 묶어서 한번에 관리할 수 있어서 편리합니다.\n",
        "\n",
        "# 아래 코드는 특성의 개수가 1 -> 6 -> 10 -> 6 -> 1개로 변하는 인공신경망입니다. \n",
        "# 또한 선형변환 이후 활성화 함수를 넣어 비선형성이 생기도록 했습니다.\n",
        "\n",
        "model = nn.Sequential(\n",
        "          nn.Linear(1,6),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(6,10),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(10,6),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(6,1),\n",
        "      )\n",
        "\n",
        "loss_func = nn.L1Loss()\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.0002)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsy40xAHsiQZ"
      },
      "source": [
        "## 모델의 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0jakOd3sJR4"
      },
      "source": [
        "loss_array = []\n",
        "for i in range(num_epoch):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(x)\n",
        "    \n",
        "    loss = loss_func(output,y_noise)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    loss_array.append(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_F6SftPSu7v"
      },
      "source": [
        "## 손실 그래프"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU4yuuC4RePA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_array)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLhQK3fUSyUI"
      },
      "source": [
        "## 학습된 모델의 결과값과 실제 목표값의 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSd6l2zQRjGG"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(x.detach().numpy(),y_noise,label=\"Original Data\")\n",
        "plt.scatter(x.detach().numpy(),output.detach().numpy(),label=\"Model Output\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpjrdBz6_g3-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOuZCNJbgO8M"
      },
      "source": [
        "# 컨볼루션 인공신경망 Convolutional Neural Network\n",
        "- MNIST 데이터\n",
        "- 합성곱 연산(CNN) \n",
        "- 맥스풀링(Max Pooling)\n",
        "- 완전연결 신경망(Fully Connected Network)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFXzochygZn4"
      },
      "source": [
        "# 파이토치 및 토치비젼 설치\n",
        "# 런타임을 GPU 모드로 바꿔서 실행하세요\n",
        "!pip install torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlMbbW9BgO8O"
      },
      "source": [
        "## 1. 학습전 세팅\n",
        "### 1) 필요한 라이브러리 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whIeu56bgO8P"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "\n",
        "# https://pytorch.org/docs/stable/torchvision/datasets.html\n",
        "# 파이토치에서는 torchvision.datasets에 MNIST 등의 다양한 데이터를 사용하기 용이하게 정리해놨습니다.\n",
        "# 이를 사용하면 데이터를 따로 학습에 맞게 정리하거나 하지 않아도 바로 사용이 가능합니다.\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "# https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transforms\n",
        "# torchvision.transforms에는 이미지 데이터를 자르거나 확대 및 다양하게 변형시키는 함수들이 구현되어 있습니다. \n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader\n",
        "# DataLoader는 전처리가 끝난 데이터들을 지정한 배치 크기에 맞게 모아서 전달해주는 역할을 합니다.\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt5vZrEUgO8U"
      },
      "source": [
        "### 2) 하이퍼파라미터 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUACXvs4gO8W"
      },
      "source": [
        "batch_size = 256\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2fUKQiugO8a"
      },
      "source": [
        "## 2. 데이터\n",
        "\n",
        "### 1) 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epKZyEd5gO8b"
      },
      "source": [
        "# https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=mnist#torchvision.datasets.MNIST\n",
        "# 첫번째 인자 root는 데이터를 저장할 위치, train은 학습용 데이터인지 테스트용 데이터인지의 여부를 의미합니다.\n",
        "\n",
        "# MNIST 데이터는 숫자 손글씨 이미지와 이에 대한 정답 쌍으로 이루어져 있습니다. \n",
        "# transform은 이미지에 대한 변형, target_transform은 정답 라벨에 대한 변형을 의미합니다.\n",
        "# transform.ToTensor()는 PIL 이미지나 Numpy 배열을 토치 텐서로 바꿔줍니다.\n",
        "\n",
        "# download는 데이터가 저장할 위치에 없을 경우 새로 다운받을지 여부입니다.\n",
        "mnist_train = dset.MNIST(root=\"../\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "mnist_test = dset.MNIST(root=\"../\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMKE4poIgO8e"
      },
      "source": [
        "### 2) 데이터셋 체크\n",
        "- getitem을 사용해도 되고 \n",
        "- 인덱싱으로도 데이터를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb4OXGWIgO8f"
      },
      "source": [
        "print(mnist_train.__getitem__(0)[0].size(), mnist_train.__len__())\n",
        "print(mnist_test.__getitem__(0)[0].size(), mnist_test.__len__())\n",
        "\n",
        "print(len(mnist_train),len(mnist_test))\n",
        "#print(mnist_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwfoDvZugO8m"
      },
      "source": [
        "### 3) DataLoader 설정\n",
        "- 사용할 데이터\n",
        "- 배치 사이즈 (batch_size)\n",
        "- 섞을지 여부 (shuffle)\n",
        "- 사용할 프로세스 개수 (num_workers)\n",
        "- 마지막에 남는 데이터의 처리 여부 (drop_last)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVXTTAtqgO8o"
      },
      "source": [
        "# https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader\n",
        "\n",
        "train_loader = DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
        "test_loader = DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf-jvTNggO8r"
      },
      "source": [
        "## 3. 모델, 손실함수, 최적화함수\n",
        "\n",
        "### 1) CNN 모델\n",
        "\n",
        "- Sequential 에 대한 설명은 4장에 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2gmbH3AgO8t"
      },
      "source": [
        "# https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d\n",
        "# https://pytorch.org/docs/stable/tensors.html?highlight=view#torch.Tensor.view\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5),             # [batch_size,1,28,28] -> [batch_size,16,24,24]\n",
        "            nn.ReLU(),                                                          # 필터의 개수는 1개(흑백이미지)에서 16개로 늘어나도록 임의로 설정했습니다. \n",
        "            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5),            # [batch_size,16,24,24] -> [batch_size,32,20,20]\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,stride=2),                               # [batch_size,32,20,20] -> [batch_size,32,10,10]\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),          # [batch_size,32,10,10] -> [batch_size,64,6,6]\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,stride=2)                                # [batch_size,64,6,6] -> [batch_size,64,3,3]\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(                                          \n",
        "            nn.Linear(64*3*3,100),                                              # [batch_size,64*3*3] -> [batch_size,100]\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,10)                                                   # [batch_size,100] -> [batch_size,10]\n",
        "        )       \n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = self.layer(x)                                                     # self.layer에 정의한 Sequential의 연산을 차례대로 다 실행합니다.\n",
        "        out = out.view(batch_size,-1)                                           # view 함수를 이용해 텐서의 형태를 [batch_size,나머지]로 바꿔줍니다. \n",
        "                                                                                # ex) 2x3 형태였던 텐서를 .view(1,-1) 해주면 1x6의 형태로 바뀝니다. .view(3,-1)이면 3x2로 바뀜.\n",
        "                                                                                # 만약 전체 텐서의 크기가 batch_size로 나누어 떨어지지 않으면 오류가 납니다.\n",
        "        out = self.fc_layer(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDPJnQS8gO8y"
      },
      "source": [
        "### 2) 손실함수 & 최적화함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ56zT9PgO8y"
      },
      "source": [
        "# gpu가 사용 가능한 경우에는 device를 gpu로 설정하고 불가능하면 cpu로 설정합니다.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# 모델을 지정한 장치로 올립니다.\n",
        "model = CNN().to(device)\n",
        "\n",
        "# 손실함수로는 크로스엔트로피를 사용합니다.\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# 최적화함수로는 Adam을 사용합니다.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5DHl_cOgO82"
      },
      "source": [
        "## 4. 학습 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsQ3UHzgO83"
      },
      "source": [
        "loss_arr =[]\n",
        "for i in range(num_epoch):\n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        loss = loss_func(output,y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if j % 1000 == 0:\n",
        "            print(loss)\n",
        "            loss_arr.append(loss.cpu().detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YG6Q37ogO87"
      },
      "source": [
        "#param_list = list(model.parameters())\n",
        "#print(param_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy_VtVa0gO8-"
      },
      "source": [
        "## 5. 학습시 손실 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OZvoJA9gO9B"
      },
      "source": [
        "plt.plot(loss_arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pXaYCUXgO9F"
      },
      "source": [
        "## 6. 테스트 데이터 정확도 측정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3buWYkSgO9I"
      },
      "source": [
        "# 맞은 개수, 전체 개수를 저장할 변수를 지정합니다.\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# 인퍼런스 모드를 위해 no_grad 해줍니다.\n",
        "with torch.no_grad():\n",
        "    # 테스트로더에서 이미지와 정답을 불러옵니다.\n",
        "    for image,label in test_loader:\n",
        "        \n",
        "        # 두 데이터 모두 장치에 올립니다.\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "\n",
        "        # 모델에 데이터를 넣고 결과값을 얻습니다.\n",
        "        output = model.forward(x)\n",
        "        \n",
        "        # https://pytorch.org/docs/stable/torch.html?highlight=max#torch.max\n",
        "        # torch.max를 이용해 최대 값 및 최대값 인덱스를 뽑아냅니다.\n",
        "        # 여기서는 최대값은 필요없기 때문에 인덱스만 사용합니다.\n",
        "        _,output_index = torch.max(output,1)\n",
        "        \n",
        "        # 전체 개수는 라벨의 개수로 더해줍니다.\n",
        "        # 전체 개수를 알고 있음에도 이렇게 하는 이유는 batch_size, drop_last의 영향으로 몇몇 데이터가 잘릴수도 있기 때문입니다.\n",
        "        total += label.size(0)\n",
        "        \n",
        "        # 모델의 결과의 최대값 인덱스와 라벨이 일치하는 개수를 correct에 더해줍니다.\n",
        "        correct += (output_index == y_).sum().float()\n",
        "    \n",
        "    # 테스트 데이터 전체에 대해 위의 작업을 시행한 후 정확도를 구해줍니다.\n",
        "    print(\"Accuracy of Test Data: {}%\".format(100*correct/total))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}